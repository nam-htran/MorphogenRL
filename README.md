# MorphogenRL

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**MorphogenRL** is a comprehensive and flexible framework for Reinforcement Learning research, focused on training diverse agent morphologies in procedurally generated environments. Built upon the powerful `TeachMyAgent` environment, this framework provides a complete pipeline for training, evaluation, and visualization, supporting various learning algorithms including PPO, Automatic Curriculum Learning (ACL), and Multi-Agent Reinforcement Learning (MARL).

The core of this project is the interaction between agents with different bodies and dynamic environments whose terrain is generated by a Compositional Pattern Producing Network (CPPN), allowing for a rich and challenging learning landscape.

<!-- Add a cool GIF or image of your project in action here -->
<!-- ![MorphogenRL Showcase](path/to/your/showcase.gif) -->

## Key Features

- **Modular Training Pipeline**: Run a full training sequence (PPO → ACL → MARL) from a single configuration file.
- **Multiple Learning Algorithms**:
    - **PPO**: Standard single-agent training using Stable Baselines 3.
    - **Automatic Curriculum Learning (ACL)**: Automatically adjusts environment difficulty based on agent performance.
    - **Multi-Agent RL (MARL)**: Supports both cooperative and interactive multi-agent scenarios using Ray RLlib.
- **Procedurally Generated Environments**: Utilizes a CPPN to create a wide variety of terrains for the `parkour` environment, ensuring agents generalize well.
- **Rich Library of Agent Morphologies**: A large selection of predefined agent bodies, from classic bipeds to spiders, fish, and climbers.
- **Powerful Tooling**: Includes scripts for:
    - Watching trained agents.
    - Recording high-quality MP4 videos of agent performance.
    - Running quick demos with random agents.
    - A comprehensive test suite to ensure code integrity.

## Project Architecture

The project is orchestrated by a main entry point, `run.py`, which dispatches tasks to various scripts. These scripts handle everything from training and testing to visualization. The training scripts interface with the `TeachMyAgent` environments, which procedurally generate terrain and instantiate the specified agent bodies.

Below is a diagram illustrating the project's workflow.

<!--
To render this diagram, you can use a Mermaid.js plugin for your IDE (like VS Code)
or paste the code into an online Mermaid editor. GitHub also renders it automatically.
-->

<!-- Add your diagram image here -->
<!-- ![Project Architecture Diagram](path/to/your/diagram.png) -->

**Mermaid.js Code for the Diagram:**

```mermaid
graph TD
    subgraph "User Interface"
        A[run.py]
    end

    subgraph "Core Commands"
        B(pipeline)
        C(train)
        D(watch)
        E(record)
        F(demo)
        G(test)
    end

    subgraph "Training Algorithms"
        H[train_ppo.py]
        I[train_acl.py]
        J[train_marl.py]
    end

    subgraph "Environment & Agents"
        K[TeachMyAgent Environment]
        L{{Procedural Terrain (CPPN)}}
        M{{Agent Bodies}}
    end

    subgraph "Utilities"
        N[watch.py]
        O[record.py]
        P[demo.py]
    end

    A --> B
    A --> C
    A --> D
    A --> E
    A --> F
    A --> G

    B --> H --> K
    B --> I --> K
    B --> J --> K

    C -- ppo --> H
    C -- acl --> I
    C -- marl --> J

    K --- L
    K --- M

    D -- uses --> N --> K
    E -- uses --> O --> K
    F -- uses --> P --> K


    style A fill:#f9f,stroke:#333,stroke-width:2px
    style K fill:#bbf,stroke:#333,stroke-width:2px
    style L fill:#lightgrey
    style M fill:#lightgrey
```

## Setup and Installation

It is highly recommended to use a `conda` environment to manage dependencies.

**1. Clone the Repository**
```bash
git clone https://github.com/nam-htran/MorphogenRL.git
cd MorphogenRL
```

**2. Create and Activate Conda Environment**
```bash
# Create a new conda environment (e.g., with Python 3.9)
conda create -n morphogenrl python=3.9

# Activate the environment
conda activate morphogenrl
```

**3. Install Dependencies**
Install all the required Python packages using pip.
```bash
pip install -r requirements.txt
```

**4. Convert Pre-trained Weights (One-time setup)**
The CPPN for procedural terrain generation uses pre-trained weights from an older TensorFlow 1.x model. A script is provided to convert them to the PyTorch format used by this project.

Run the following command once before starting any training or demos:
```bash
python run.py convert
```
This will create a `.pt` file in `TeachMyAgent/environments/envs/PCGAgents/CPPN/weights/`, allowing the CPPN to function correctly.

## Usage

All functionalities are accessible through `run.py`.

### Running the Full Pipeline
To run the complete training pipeline as defined in `configs/main_pipeline.yaml`, use the `pipeline` command.

```bash
python run.py pipeline --config configs/main_pipeline.yaml
```
- **`--watch`**: Add this flag to watch the agent's performance after each training stage completes.
- **`--render-stages`**: Add this flag to render the environment during the PPO and ACL training stages (slows down training).

### Training Individual Models
You can train specific algorithms individually.

**Train PPO:**
```bash
python run.py train ppo --run_id my_ppo_run --body classic_bipedal --total_timesteps 500000
```

**Train with Automatic Curriculum Learning (ACL):**
```bash
python run.py train acl --run_id my_acl_run --body climbing_profile_chimpanzee --total_stages 100
```

**Train Multi-Agent (MARL):**
```bash
python run.py train marl --run_id my_marl_run --mode interactive --n-agents 2 --body classic_bipedal --iterations 50
```

### Watching a Trained Model
Visualize the performance of a saved model (`.zip` file).

```bash
python run.py watch --model_path output/ppo/my_ppo_run/models/ppo_model_final.zip --body classic_bipedal --num_episodes 5
```

### Recording a Video
Record the agent's performance and save it as an MP4 file.

```bash
python run.py record --model_path output/ppo/my_ppo_run/models/ppo_model_final.zip \
                     -o recordings/my_agent_performance.mp4 \
                     --body classic_bipedal \
                     --num_episodes 3
```

### Running a Demo
Launch an environment with a random agent to test environments and bodies.

```bash
python run.py demo --env parkour --body spider --steps 1000
```

### Running Tests
To ensure the integrity of the environments and training scripts, run the integrated test suite.

```bash
# Run a quick pipeline integration test
python run.py test

# Run a comprehensive check of all environments and bodies
python scripts/check_all.py
```

## Environments and Agent Bodies

### Environments
- **`stump`**: A simpler environment where agents must traverse a track with procedurally placed stumps of varying height and width.
- **`parkour`**: A more complex environment featuring terrain and ceilings generated by a CPPN. It can include water and climbable "creepers," making it suitable for a wide range of agent types.

### Available Agent Bodies
This framework supports a large variety of agent morphologies, each presenting unique control challenges.

- **Walkers**:
    - `small_bipedal`
    - `classic_bipedal`
    - `big_quadru`
    - `spider`
    - `millipede`
    - `wheel`
    - `profile_chimpanzee`
    - `old_classic_bipedal` (legacy version)
    - `old_big_quadru` (legacy version)
- **Swimmers**:
    - `fish`
- **Climbers**:
    - `climbing_profile_chimpanzee`
    - `climbing_chest_profile_chimpanzee`
- **Amphibians**:
    - `amphibious_bipedal`

You can specify the desired body using the `--body` argument in any command.

<!-- Add an image collage of different agents -->
<!-- ![Agent Collage](path/to/your/collage.png) -->

## Acknowledgements

This project is built upon and extends the excellent procedural environments from the **TeachMyAgent** framework. Their work on creating dynamic, parameterized environments was foundational to this research.

## License

This project is licensed under the MIT License. See the `LICENSE` file for details.