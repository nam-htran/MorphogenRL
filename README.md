# MorphogenRL

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**MorphogenRL** is a comprehensive and flexible framework for Reinforcement Learning research, focused on training diverse agent morphologies in procedurally generated environments. Built upon the powerful `TeachMyAgent` environment, this framework provides a complete pipeline for training, evaluation, and visualization, supporting various learning algorithms including PPO, Automatic Curriculum Learning (ACL), and Multi-Agent Reinforcement Learning (MARL).

The core of this project is the interaction between agents with different bodies and dynamic environments whose terrain is generated by a Compositional Pattern Producing Network (CPPN), allowing for a rich and challenging learning landscape.
<img width="2558" height="1366" alt="{523FB519-2941-4449-A476-581D6F0D7A5A}" src="https://github.com/user-attachments/assets/50ab7e5e-96be-46fb-aed2-e2fa99239cc5" />

## Key Features

- **Modular Training Pipeline**: Run a full training sequence (PPO → ACL → MARL) from a single configuration file.
- **Multiple Learning Algorithms**:
    - **PPO**: Standard single-agent training using Stable Baselines 3.
    - **Automatic Curriculum Learning (ACL)**: Automatically adjusts environment difficulty based on agent performance.
    - **Multi-Agent RL (MARL)**: Supports both cooperative and interactive multi-agent scenarios using Ray RLlib.
- **Procedurally Generated Environments**: Utilizes a CPPN to create a wide variety of terrains for the `parkour` environment, ensuring agents generalize well.
- **Rich Library of Agent Morphologies**: A large selection of predefined agent bodies, from classic bipeds to spiders, fish, and climbers.
- **Powerful Tooling**: Includes scripts for:
    - Watching trained agents.
    - Recording high-quality MP4 videos of agent performance.
    - Running quick demos with random agents.
    - A comprehensive test suite to ensure code integrity.

## Project Architecture

The project is orchestrated by a main entry point, `run.py`, which dispatches tasks to various scripts. These scripts handle everything from training and testing to visualization. The training scripts interface with the `TeachMyAgent` environments, which procedurally generate terrain and instantiate the specified agent bodies.

Below is a diagram illustrating the project's workflow.

<img width="2238" height="1282" alt="Mermaid Chart - Create complex, visual diagrams with text -2025-10-26-000644" src="https://github.com/user-attachments/assets/54a31301-f566-4b93-8f61-1ab44e444fd0" />


## Setup and Installation

It is highly recommended to use a `conda` environment to manage dependencies.

**1. Clone the Repository**
```bash
git clone https://github.com/nam-htran/MorphogenRL.git
cd MorphogenRL
```

**2. Create and Activate Conda Environment**
```bash
# Create a new conda environment (recommend 3.11, we upgrade library from TeachMyAgent old library version to 3.11)
conda create -n morphogenrl python=3.11

# Activate the environment
conda activate morphogenrl
```

> **Important Prerequisite: SWIG Installation**
> Before installing the Python packages, you must install SWIG, which is a dependency for the Box2D physics engine used in the environments. The version used during development was **4.0.2**.
> 
> **On Linux (Ubuntu/Debian):**
> Open your terminal and run the following command to install SWIG and CMake:
> ```bash
> sudo apt-get update && sudo apt-get install swig cmake
> ```
> 
> **On Windows:**
> 1.  Download SWIG for Windows from the [official SWIG website](http://www.swig.org/download.html). Look for `swigwin` (e.g., `swigwin-4.0.2.zip`).
> 2.  Extract the ZIP file to a permanent location on your computer, for example, `C:\swigwin-4.0.2`.
> 3.  Add the SWIG directory to your system's `PATH` environment variable:
>     -   Search for "Edit the system environment variables" in the Start Menu and open it.
>     -   Click on the "Environment Variables..." button.
>     -   In the "System variables" section, find and select the `Path` variable, then click "Edit...".
>     -   Click "New" and paste the full path to your SWIG directory (e.g., `C:\swigwin-4.0.2`).
>     -   Click OK to close all windows.
> 4.  **Verify the installation:** Open a **new** Command Prompt or PowerShell window and run `swig -version`. If it shows the version number, the installation was successful.

**3. Install Dependencies**
Once SWIG is installed and configured, install all the required Python packages using pip.
```bash
pip install -r requirements.txt
```

**4. Convert Pre-trained Weights (One-time setup)**
The CPPN for procedural terrain generation uses pre-trained weights from an older TensorFlow 1.x model. A script is provided to convert them to the PyTorch format used by this project.

Run the following command once before starting any training or demos:
```bash
python run.py convert
```
This will create a `.pt` file in `TeachMyAgent/environments/envs/PCGAgents/CPPN/weights/`, allowing the CPPN to function correctly.

## Usage

All functionalities are accessible through `run.py`.

### Running the Full Pipeline
To run the complete training pipeline as defined in `configs/main_pipeline.yaml`, use the `pipeline` command.

```bash
python run.py pipeline --config configs/main_pipeline.yaml
```
- **`--watch`**: Add this flag to watch the agent's performance after each training stage completes.
- **`--render-stages`**: Add this flag to render the environment during the PPO and ACL training stages (slows down training).

### Training Individual Models
You can train specific algorithms individually.

**Train PPO:**
```bash
python run.py train ppo --run_id my_ppo_run --body classic_bipedal --total_timesteps 500000
```

**Train with Automatic Curriculum Learning (ACL):**
```bash
python run.py train acl --run_id my_acl_run --body climbing_profile_chimpanzee --total_stages 100
```

**Train Multi-Agent (MARL):**
```bash
python run.py train marl --run_id my_marl_run --mode interactive --n-agents 2 --body classic_bipedal --iterations 50
```

### Watching a Trained Model
Visualize the performance of a saved model (`.zip` file).

```bash
python run.py watch --model_path output/ppo/my_ppo_run/models/ppo_model_final.zip --body classic_bipedal --num_episodes 5
```

### Recording a Video
Record the agent's performance and save it as an MP4 file.

```bash
python run.py record --model_path output/ppo/my_ppo_run/models/ppo_model_final.zip \
                     -o recordings/my_agent_performance.mp4 \
                     --body classic_bipedal \
                     --num_episodes 3
```

### Running a Demo
Launch an environment with a random agent to test environments and bodies.

```bash
python run.py demo --env parkour --body spider --steps 1000
```

### Running Tests
To ensure the integrity of the environments and training scripts, run the integrated test suite.

```bash
# Run a quick pipeline integration test
python run.py test

# Run a comprehensive check of all environments and bodies
python scripts/check_all.py
```

## Environments and Agent Bodies

### Environments
- **`stump`**: A simpler environment where agents must traverse a track with procedurally placed stumps of varying height and width.
- **`parkour`**: A more complex environment featuring terrain and ceilings generated by a CPPN. It can include water and climbable "creepers," making it suitable for a wide range of agent types.

### Available Agent Bodies
This framework supports a large variety of agent morphologies, each presenting unique control challenges.

- **Walkers**:
    - `small_bipedal`
    - `classic_bipedal`
    - `big_quadru`
    - `spider`
    - `millipede`
    - `wheel`
    - `profile_chimpanzee`
    - `old_classic_bipedal` (legacy version)
    - `old_big_quadru` (legacy version)
- **Swimmers**:
    - `fish`
- **Climbers**:
    - `climbing_profile_chimpanzee`
    - `climbing_chest_profile_chimpanzee`
- **Amphibians**:
    - `amphibious_bipedal`

You can specify the desired body using the `--body` argument in any command.


## Acknowledgements

This project is built upon and extends the excellent procedural environments from the **TeachMyAgent** framework. Their work on creating dynamic, parameterized environments was foundational to this research.

## License
This project is licensed under the MIT License. See the `LICENSE` file for details.
This project includes code from TeachMyAgent (© 2021 Flowers Team), licensed under the MIT License.
See the LICENSE file for details.
