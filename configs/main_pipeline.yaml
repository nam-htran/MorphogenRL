WATCH:
  enabled: false 
  fast_forward: true
  auto_skip_stuck: true

PPO:
  enabled: true 
  run_id: "ppo_final_stable_run"
  env: "parkour"
  body: "classic_bipedal"
  
  total_timesteps: 10000000
  save_freq: 100000
  n_envs: 16
  horizon: 5000

  ppo_config:
    gamma: 0.99
    n_steps: 1024
    ent_coef: 0.01 
    learning_rate: "lambda progress_remaining: progress_remaining * 3e-4"
    vf_coef: 0.5
    max_grad_norm: 0.5
    n_epochs: 10
    batch_size: 64
    gae_lambda: 0.95
    clip_range: 0.2 

ACL:
  enabled: true
  run_id: "acl_final_run"
  env: "parkour"
  body: "climbing_profile_chimpanzee"
  total_stages: 1000
  student_steps_per_stage: 32768 
  eval_episodes: 20
  mastery_threshold: 200.0
  difficulty_increment: 0.005
  horizon: 5000


MARL:
  enabled: true 
  run_id: "marl_final_tuned_run"
  mode: "interactive"
  n_agents: 2
  body: "classic_bipedal"
  num_workers: 2
  num_gpus: 2
  horizon: 5000

  shared_policy: true
  use_cc: true

  use_tune: false
  iterations: 2500
  
  tune_config:
    run_config:
      name: "marl_final_tuning"
      stop:
        env_runners/episode_reward_mean: 280
        training_iteration: 1000
      checkpoint_config:
        num_to_keep: 3
        checkpoint_score_attribute: "env_runners/episode_reward_mean" 
        checkpoint_score_order: "max"

    search_space:
      training:
        lr: "tune.grid_search([0.0003, 0.0001, 0.00005])"
        gamma: 0.99
        lambda_: "tune.uniform(0.9, 1.0)"
        clip_param: "tune.choice([0.1, 0.2])"
        entropy_coeff: "tune.choice([0.0, 0.005, 0.01])"
      
      rl_module:
        model_config:
          fcnet_hiddens: "tune.choice([[512, 512], [256, 256]])"
          fcnet_activation: "tanh"
