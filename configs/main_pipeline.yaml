PIPELINE_SETTINGS:
  transfer_learning: true

WATCH:
  enabled: false 
  fast_forward: true
  auto_skip_stuck: true

PPO:
  enabled: true
  run_id: "ultimate_pipeline_ppo_pretrain"
  env: "parkour"
  body: "classic_bipedal"
  
  total_timesteps: 2000000 
  save_freq: 500000
  n_envs: 32
  horizon: 5000

  reward_shaping:
    progress_multiplier: 200.0
    velocity_multiplier: 0.5
    torque_penalty_multiplier: 30.0
    alive_bonus: 0.02

  ppo_config:
    gamma: 0.99 
    n_steps: 4096
    ent_coef: 0.005
    learning_rate: 3e-4
    n_epochs: 10
    batch_size: 64

ACL:
  enabled: true
  run_id: "ultimate_pipeline_acl_generalist"
  env: "parkour"
  body: "classic_bipedal"
  
  student_steps_per_stage: 250000
  total_stages: 24 

  eval_episodes: 10
  mastery_threshold: -50.0
  difficulty_increment: 0.042
  horizon: 5000
  n_envs: 32
  seed: 42
  
  curriculum_replay:
    enabled: true
    replay_ratio: 0.25

  reward_shaping:
    progress_multiplier: 200.0
    velocity_multiplier: 0.5
    torque_penalty_multiplier: 30.0
    alive_bonus: 0.02

  ppo_config:
    learning_rate: 0.0003
    buffer_size: 1000000 
    batch_size: 256
    ent_coef: 'auto'
    gamma: 0.99
    learning_starts: 10000

MARL:
  enabled: true
  run_id: "ultimate_pipeline_marl_cooperation"
  mode: "interactive"
  n_agents: 2
  body: "classic_bipedal"
  num_workers: 4
  num_gpus: 2
  horizon: 5000
  
  reward_type: "shared"
  shared_policy: true
  use_cc: true
  use_tune: false
  
  iterations: 150
  
  ppo_config:
    training:
      gamma: 0.99
      lr: 0.0003
      lambda_: 0.95
      clip_param: 0.2
      entropy_coeff: 0.01
      train_batch_size: 16384 
    
    model:
      fcnet_hiddens: [64, 64] 
      fcnet_activation: "tanh"
      
    env_runners:
      rollout_fragment_length: 1024