run_id: "marl_coop_run"
mode: "interactive"
n_agents: 2
iterations: 150
num_workers: 4
num_gpus: 1

reward_type: "shared"
shared_policy: true
use_cc: true

use_tune: false 
tune_config:
  num_samples: 20 
  stopper:
    patience: 5
    metric: "episode_reward_mean"
  search_space:
    training:
      lr: "tune.loguniform(1e-5, 1e-3)"
      gamma: "tune.choice([0.99, 0.995])"
      lambda_: "tune.uniform(0.9, 1.0)"
      clip_param: "tune.choice([0.1, 0.2, 0.3])"
      entropy_coeff: "tune.loguniform(0.001, 0.05)"
    model:
      fcnet_hiddens: "tune.choice([[64, 64], [128, 128], [256, 256]])"

ppo_config:
  training:
    gamma: 0.99
    lr: 0.0003
    lambda_: 0.95
    clip_param: 0.2
    entropy_coeff: 0.01
    train_batch_size: 16384 
  
  model:
    fcnet_hiddens: [128, 128] 
    fcnet_activation: "tanh"
    
  env_runners:
    rollout_fragment_length: 1024